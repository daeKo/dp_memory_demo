# DP Memory Example
This is a short demo for training a simple two-layer LSTM character-level language model using differentially private Adam and regular one. It is based on the language model example given in https://github.com/tensorflow/privacy/blob/master/tutorials/lm_dpsgd_tutorial.py and shows the memorization effect occuring in recurrent neural networks and how to limit it.

## Installation

The usually easiest way to run the notebook is by running `setup.sh`. This will create a virtual environment, install the requirements and register it as ipykernel for the jupyter notebook. It will also print the name of the kernel you have to select.

If you are having trouble setting everything up, you can try to manually install everything and might want to change versions of some packages.

## Usage

The notebook should guide you through everything, so assuming everything installed correctly, you should just need to follow the instructions there.
